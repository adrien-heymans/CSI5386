{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"bb4dca2e5c7a4e46b338bd70cc0472cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_684e16700fc74cf68b16ff98c9b8fee9","IPY_MODEL_257c869dd2494ffd94e71dd9e4ff0600","IPY_MODEL_ded8cdbcbcca48e5ac8288297f9b87db"],"layout":"IPY_MODEL_595cc3ea92854eb2a9b6554a7ce1c067"}},"684e16700fc74cf68b16ff98c9b8fee9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1826800942a141f6a0620c495e6e58aa","placeholder":"​","style":"IPY_MODEL_cca594a05cd046d29e9cdc0fe75ba2fb","value":"Downloading: 100%"}},"257c869dd2494ffd94e71dd9e4ff0600":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_320e3b510d0d432cbf01a2a858042293","max":152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46205815ab6d4690821495dd6a25ad8c","value":152}},"ded8cdbcbcca48e5ac8288297f9b87db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_289b8423282a438aa68b774e6e9345db","placeholder":"​","style":"IPY_MODEL_00051fa901f143ec8f10e66da4cbb777","value":" 152/152 [00:00&lt;00:00, 4.74kB/s]"}},"595cc3ea92854eb2a9b6554a7ce1c067":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1826800942a141f6a0620c495e6e58aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cca594a05cd046d29e9cdc0fe75ba2fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"320e3b510d0d432cbf01a2a858042293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46205815ab6d4690821495dd6a25ad8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"289b8423282a438aa68b774e6e9345db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00051fa901f143ec8f10e66da4cbb777":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2089cd3994446e8a728cdcd0a61b80d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29483930506245e484b82a60fd15e7fd","IPY_MODEL_d6f5a7d95ef945bda552d808e76e0b11","IPY_MODEL_4cc26f38c1e8456bac0115cfd8bae039"],"layout":"IPY_MODEL_c6e1a00d9bd4474fb49385e012f2a36d"}},"29483930506245e484b82a60fd15e7fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0db5eae65f2c4e7ab4d0bc9726ede44a","placeholder":"​","style":"IPY_MODEL_83823b89ecdd464b9d2ed5ff6da55d48","value":"Downloading: 100%"}},"d6f5a7d95ef945bda552d808e76e0b11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5620db8cc67c4529874d3b85f3fb9eaf","max":508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0fcf1046776461bb2080246a320f5cf","value":508}},"4cc26f38c1e8456bac0115cfd8bae039":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd73c9ba1c204118a5674c77b644c40e","placeholder":"​","style":"IPY_MODEL_0c15942888bb46d288ca013975b023a0","value":" 508/508 [00:00&lt;00:00, 4.26kB/s]"}},"c6e1a00d9bd4474fb49385e012f2a36d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db5eae65f2c4e7ab4d0bc9726ede44a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83823b89ecdd464b9d2ed5ff6da55d48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5620db8cc67c4529874d3b85f3fb9eaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0fcf1046776461bb2080246a320f5cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd73c9ba1c204118a5674c77b644c40e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c15942888bb46d288ca013975b023a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6505781354ac45f7912e30fdd53202eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb783fb42d5e43d9a88c823c024a8230","IPY_MODEL_a3a54d1b4c37497885377e7301a950ad","IPY_MODEL_36410bbc25e340b6a993a40414742af9"],"layout":"IPY_MODEL_f300ed208eac411c9751e4cb8f8dcd09"}},"fb783fb42d5e43d9a88c823c024a8230":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65ca383e49d24a45ac786c7c531134d4","placeholder":"​","style":"IPY_MODEL_831f670d5e3b4304af1401590af1e25f","value":"Downloading: 100%"}},"a3a54d1b4c37497885377e7301a950ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2757ba1673eb4c518efa21c1dc5269e9","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59e1132e254948cfb5996e4d4030445e","value":213450}},"36410bbc25e340b6a993a40414742af9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0609ceb4425948b384135678e99cae10","placeholder":"​","style":"IPY_MODEL_55d9e7bff04b47a2aa2d274dedd913e2","value":" 213k/213k [00:00&lt;00:00, 252kB/s]"}},"f300ed208eac411c9751e4cb8f8dcd09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65ca383e49d24a45ac786c7c531134d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"831f670d5e3b4304af1401590af1e25f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2757ba1673eb4c518efa21c1dc5269e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59e1132e254948cfb5996e4d4030445e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0609ceb4425948b384135678e99cae10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d9e7bff04b47a2aa2d274dedd913e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f16df48d576f41e0bfb4b3c7b0bcf75b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f25514de9baa415ca31dcf51633c9527","IPY_MODEL_1f6331d4052a4712b6f36adaba1fc117","IPY_MODEL_7912d8bd0ef24119893408dfc4677406"],"layout":"IPY_MODEL_b9857309f2cd429fa730cd4f9be37115"}},"f25514de9baa415ca31dcf51633c9527":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46fb4552f4f74a5398a67f0e08db0bf5","placeholder":"​","style":"IPY_MODEL_14f4b4485c72409196e435383be28b13","value":"Downloading: 100%"}},"1f6331d4052a4712b6f36adaba1fc117":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43e70341aace4278b93cc44a593896dc","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02b1fc6afc9c4e6da75e3f245a11c3ef","value":112}},"7912d8bd0ef24119893408dfc4677406":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbc605b44cc440c88525556b14195c58","placeholder":"​","style":"IPY_MODEL_bd1dfedf5c084c228e51349bf6198827","value":" 112/112 [00:00&lt;00:00, 798B/s]"}},"b9857309f2cd429fa730cd4f9be37115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46fb4552f4f74a5398a67f0e08db0bf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14f4b4485c72409196e435383be28b13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43e70341aace4278b93cc44a593896dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02b1fc6afc9c4e6da75e3f245a11c3ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbc605b44cc440c88525556b14195c58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd1dfedf5c084c228e51349bf6198827":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1de739696ea444729db0788e2b1b2ed8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92662c869f8f41799729bd8592ee685a","IPY_MODEL_393f18bf8fc94064b2e5917536e99182","IPY_MODEL_acd17be5aa46494fa2020b599ad80e64"],"layout":"IPY_MODEL_a84e97fb97004b479d353d4b0d603d8f"}},"92662c869f8f41799729bd8592ee685a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa883edee55948c99581ef9cff2747b4","placeholder":"​","style":"IPY_MODEL_84991917267c4ce3ae1e09e96af20b3d","value":"100%"}},"393f18bf8fc94064b2e5917536e99182":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f247859b5535421bbe5a05bac7f5bfb6","max":23,"min":0,"orientation":"horizontal","style":"IPY_MODEL_902d050298fe4362870626b3a02cb4f1","value":23}},"acd17be5aa46494fa2020b599ad80e64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc5a3b48e2b6408dacd2ebafa4a96707","placeholder":"​","style":"IPY_MODEL_813b15fcb17840ae9581dbbb41c1f783","value":" 23/23 [11:29&lt;00:00, 22.82s/ba]"}},"a84e97fb97004b479d353d4b0d603d8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa883edee55948c99581ef9cff2747b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84991917267c4ce3ae1e09e96af20b3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f247859b5535421bbe5a05bac7f5bfb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902d050298fe4362870626b3a02cb4f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc5a3b48e2b6408dacd2ebafa4a96707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"813b15fcb17840ae9581dbbb41c1f783":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d91dd32ea36b4a078f6c232df0072b65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_691f58131adf471dbf41caa2b995d157","IPY_MODEL_83702624b3394d5a95c4c1094a31f341","IPY_MODEL_f4e7eb54396249aab0fe2a0596eae3f5"],"layout":"IPY_MODEL_72491821136c4516b51464e7f63ab940"}},"691f58131adf471dbf41caa2b995d157":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3eac1599a74f899afb0df49787f602","placeholder":"​","style":"IPY_MODEL_490772e75bc344a89f232456177261c3","value":"100%"}},"83702624b3394d5a95c4c1094a31f341":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29df3027a21349988da0f9a234d2082d","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5ac247ec7884cdab88df9f1a67e5476","value":5}},"f4e7eb54396249aab0fe2a0596eae3f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73bcddbd8e274a85afc93d9de0c617cc","placeholder":"​","style":"IPY_MODEL_05e68169ddec477a81de8f9dabb52006","value":" 5/5 [01:29&lt;00:00, 14.86s/ba]"}},"72491821136c4516b51464e7f63ab940":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3eac1599a74f899afb0df49787f602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"490772e75bc344a89f232456177261c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29df3027a21349988da0f9a234d2082d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5ac247ec7884cdab88df9f1a67e5476":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73bcddbd8e274a85afc93d9de0c617cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05e68169ddec477a81de8f9dabb52006":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31ac8b722fd348059b8e0c9961d85d60":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d54603d1b0c34399be9250bdab7b95bc","IPY_MODEL_5bad802757624904beb52fb178303684","IPY_MODEL_e5cc67e6d986406e99b16be1a3224ebf"],"layout":"IPY_MODEL_1b85f54505df4764b5295f890e686f4a"}},"d54603d1b0c34399be9250bdab7b95bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926badbd62f44358b6e9821b6de9cdc6","placeholder":"​","style":"IPY_MODEL_d020f21b4b0f4763911708ce771759d9","value":"Downloading: 100%"}},"5bad802757624904beb52fb178303684":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb8f8fb93be44edbaeada8e8c04b705","max":433294681,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a7385f8362e418485bb53912642b985","value":433294681}},"e5cc67e6d986406e99b16be1a3224ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a754fc68c8674fe49d2bab2c606f62f1","placeholder":"​","style":"IPY_MODEL_0fd4e9bc5ffa430ea03d8ba08da19af6","value":" 433M/433M [00:12&lt;00:00, 31.1MB/s]"}},"1b85f54505df4764b5295f890e686f4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926badbd62f44358b6e9821b6de9cdc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d020f21b4b0f4763911708ce771759d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb8f8fb93be44edbaeada8e8c04b705":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a7385f8362e418485bb53912642b985":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a754fc68c8674fe49d2bab2c606f62f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fd4e9bc5ffa430ea03d8ba08da19af6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"537a9ab0e62a4d7f82ac639698a8c6f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c7f5152c00b46788ccd678845ea39f3","IPY_MODEL_be460ae54b044c168d9baf5b066837a8","IPY_MODEL_d7984446a4114932969c78899ba02448"],"layout":"IPY_MODEL_7351950d668a420d947fdb55e1ea76cf"}},"1c7f5152c00b46788ccd678845ea39f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61c988f3d6f44d8d993d8753fe039bbb","placeholder":"​","style":"IPY_MODEL_ee396aa67bbb480ebf9878f11e252bc3","value":"100%"}},"be460ae54b044c168d9baf5b066837a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89311c8c4dca4679b31f38719da537e2","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcabd066470e40f980bcec7fa9e9bd93","value":2}},"d7984446a4114932969c78899ba02448":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9b6e62759f9485fba4f3cd2051dbcaa","placeholder":"​","style":"IPY_MODEL_35d211efbb6b4f59b8e23dcd47cb120c","value":" 2/2 [00:00&lt;00:00,  4.67it/s]"}},"7351950d668a420d947fdb55e1ea76cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61c988f3d6f44d8d993d8753fe039bbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee396aa67bbb480ebf9878f11e252bc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89311c8c4dca4679b31f38719da537e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcabd066470e40f980bcec7fa9e9bd93":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9b6e62759f9485fba4f3cd2051dbcaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35d211efbb6b4f59b8e23dcd47cb120c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9916cab4cbe64cd1841339c4d5473f70":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9ea35bfd9584c8fb345aed180991556","IPY_MODEL_a5d81889a8b144d5b60723f00d95ebac","IPY_MODEL_561e8705922c457aa00999261fae0723"],"layout":"IPY_MODEL_012c12e5fbdb47e2835ca47fd2a6090b"}},"e9ea35bfd9584c8fb345aed180991556":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a98f9087a2d64d86b6dda644886e8231","placeholder":"​","style":"IPY_MODEL_3cd1fa527dc5479eacdc7e1827f70a22","value":"Downloading builder script: 100%"}},"a5d81889a8b144d5b60723f00d95ebac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b76c40dfd5b846779cb3eb697b86c906","max":5191,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c00a64b9684f3bb3b2833204843d78","value":5191}},"561e8705922c457aa00999261fae0723":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_665de3040ced488c8511ed21563261be","placeholder":"​","style":"IPY_MODEL_01f47e2879f64cbf92a29991c1ba7e46","value":" 5.19k/5.19k [00:00&lt;00:00, 161kB/s]"}},"012c12e5fbdb47e2835ca47fd2a6090b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a98f9087a2d64d86b6dda644886e8231":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cd1fa527dc5479eacdc7e1827f70a22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b76c40dfd5b846779cb3eb697b86c906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c00a64b9684f3bb3b2833204843d78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"665de3040ced488c8511ed21563261be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01f47e2879f64cbf92a29991c1ba7e46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f771b3defd0a40ff973053ff040c33cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f1781e47d9741ab9887f7b4c7afcafe","IPY_MODEL_c6e1988110a34e489c4434e7da441717","IPY_MODEL_ee34ea16cc4149e89d80e5da26271c16"],"layout":"IPY_MODEL_9cd750a52ce64a46942b4e498dac85dd"}},"5f1781e47d9741ab9887f7b4c7afcafe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_482435bc6ac640a5b7997b8900295f0d","placeholder":"​","style":"IPY_MODEL_dbd2591c7e8843ffa39230d1e15d15f5","value":"Downloading metadata: 100%"}},"c6e1988110a34e489c4434e7da441717":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19ac1c358cd841cd984d5f3d40b3edbb","max":1911,"min":0,"orientation":"horizontal","style":"IPY_MODEL_145ef5c283894b39b56d85a49a058963","value":1911}},"ee34ea16cc4149e89d80e5da26271c16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_427a0c800bf04ca9ba730ede4024fd92","placeholder":"​","style":"IPY_MODEL_3f29f012cf8d423ebabb45a2d3d2efc0","value":" 1.91k/1.91k [00:00&lt;00:00, 57.2kB/s]"}},"9cd750a52ce64a46942b4e498dac85dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"482435bc6ac640a5b7997b8900295f0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbd2591c7e8843ffa39230d1e15d15f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19ac1c358cd841cd984d5f3d40b3edbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"145ef5c283894b39b56d85a49a058963":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"427a0c800bf04ca9ba730ede4024fd92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f29f012cf8d423ebabb45a2d3d2efc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70abeb896bee40798ebf209c177c663b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d9933b5475e49e79a23311961afe874","IPY_MODEL_aecffd0c204b49b894534c81c6fb14bc","IPY_MODEL_bd5203fe318b46e8b652647043cefd8c"],"layout":"IPY_MODEL_2242e1d41d6b43958d9d65bc6d700cdb"}},"6d9933b5475e49e79a23311961afe874":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec854c2a9093427cb57468319faf3fe2","placeholder":"​","style":"IPY_MODEL_1e365e9435a949d3a3309e42e7b274a4","value":"Downloading readme: 100%"}},"aecffd0c204b49b894534c81c6fb14bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5f2e2f7fafa48989780347faa3711df","max":15517,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79bf500604ef494cab62b730638b613d","value":15517}},"bd5203fe318b46e8b652647043cefd8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_852a9a7db8434d5387e5c3f637a3dce0","placeholder":"​","style":"IPY_MODEL_47ea46f9f6b842718db6c38e80ee8018","value":" 15.5k/15.5k [00:00&lt;00:00, 18.3kB/s]"}},"2242e1d41d6b43958d9d65bc6d700cdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec854c2a9093427cb57468319faf3fe2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e365e9435a949d3a3309e42e7b274a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5f2e2f7fafa48989780347faa3711df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79bf500604ef494cab62b730638b613d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"852a9a7db8434d5387e5c3f637a3dce0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47ea46f9f6b842718db6c38e80ee8018":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bca99cb4d574268815f67b23f235152":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e22aafd891464da39b4e67359db2b325","IPY_MODEL_23a42a346ca841fa9ed086fda09894ca","IPY_MODEL_f38cff33fb244f839dd6c39172d00e02"],"layout":"IPY_MODEL_eaa4052e469a4333930405c3989beb82"}},"e22aafd891464da39b4e67359db2b325":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae2d9c01648248a2a43df01edfc77d01","placeholder":"​","style":"IPY_MODEL_2feba317fb784f0cbc54c76573517df6","value":"Downloading data: 100%"}},"23a42a346ca841fa9ed086fda09894ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83db239b602b4e30a249e1029c79940a","max":18309308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84ced86bd74440149cf3141173de4080","value":18309308}},"f38cff33fb244f839dd6c39172d00e02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_466d0a93c24e40f6a7afc0c9a6691ac0","placeholder":"​","style":"IPY_MODEL_93bccf280af448a992a809233b5f9eb8","value":" 18.3M/18.3M [00:00&lt;00:00, 49.2MB/s]"}},"eaa4052e469a4333930405c3989beb82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae2d9c01648248a2a43df01edfc77d01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2feba317fb784f0cbc54c76573517df6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83db239b602b4e30a249e1029c79940a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84ced86bd74440149cf3141173de4080":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"466d0a93c24e40f6a7afc0c9a6691ac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93bccf280af448a992a809233b5f9eb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24fb9610e69847d096ec998bd47a0110":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2e41d6aa61d42e48485889a16530acf","IPY_MODEL_5ade08fc11a446358a8c2d3615165557","IPY_MODEL_3a22971b035e4befacb4994675f79269"],"layout":"IPY_MODEL_6918ed631092446cae9ead450aa175c8"}},"c2e41d6aa61d42e48485889a16530acf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57fc219be1c1474493eb8c7bcd22e198","placeholder":"​","style":"IPY_MODEL_95f7df71f115499ea8860ddb8e4aa36b","value":"Generating train split:  98%"}},"5ade08fc11a446358a8c2d3615165557":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac892b35e68d419caf4d7fc048eae54e","max":22450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cd41a40f27a4f298893b40b13d64888","value":22450}},"3a22971b035e4befacb4994675f79269":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64835cb77d7440738de43e1c9562ee2c","placeholder":"​","style":"IPY_MODEL_d8f90668029b42aaa6c1ab395bc4c2c8","value":" 22000/22450 [00:07&lt;00:00, 2650.41 examples/s]"}},"6918ed631092446cae9ead450aa175c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"57fc219be1c1474493eb8c7bcd22e198":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95f7df71f115499ea8860ddb8e4aa36b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac892b35e68d419caf4d7fc048eae54e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cd41a40f27a4f298893b40b13d64888":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64835cb77d7440738de43e1c9562ee2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8f90668029b42aaa6c1ab395bc4c2c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e85bac5532514cbb833d2d9445720681":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_addfb9739cb64eed8ec82e5f920007bb","IPY_MODEL_330f5a62fa5d4490bb5c2ee10dd01da7","IPY_MODEL_0be57d91afbd4109901031c1b1ea69d7"],"layout":"IPY_MODEL_223d787944dc40e4b5b5ff981e1a002f"}},"addfb9739cb64eed8ec82e5f920007bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7fdebceeafc462c9efd780e5810c692","placeholder":"​","style":"IPY_MODEL_47eaf2833a7147e79f1a54194a3ce6d1","value":"Generating test split: 100%"}},"330f5a62fa5d4490bb5c2ee10dd01da7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a900d5f49dd4d35a3868e67bea9256f","max":4182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cfa206eab4f47cdadb2174792ce890c","value":4182}},"0be57d91afbd4109901031c1b1ea69d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5e2a4777ef04edda7b021acc32b2a1d","placeholder":"​","style":"IPY_MODEL_a2cc8f1f991c4889ac9bf1840aa185c0","value":" 4182/4182 [00:12&lt;00:00, 1995.35 examples/s]"}},"223d787944dc40e4b5b5ff981e1a002f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7fdebceeafc462c9efd780e5810c692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47eaf2833a7147e79f1a54194a3ce6d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a900d5f49dd4d35a3868e67bea9256f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cfa206eab4f47cdadb2174792ce890c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5e2a4777ef04edda7b021acc32b2a1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2cc8f1f991c4889ac9bf1840aa185c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23c93efaf8d844f1b90391ded8348c27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fae253090d5e411c916708b9ee5d159a","IPY_MODEL_9f8d54470fe84155a0eac42d22e70e81","IPY_MODEL_f2becab02e8743c394fe4a963b444ece"],"layout":"IPY_MODEL_6ee960c10f6b4478aabdae65d4eed53d"}},"fae253090d5e411c916708b9ee5d159a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0443fb9ce76433998693eb2a713a561","placeholder":"​","style":"IPY_MODEL_d0eb34be06c749f49040cf03cda07321","value":"100%"}},"9f8d54470fe84155a0eac42d22e70e81":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fdee202909f41968fa138d97d5a0378","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59e748961ca54b57b319a190ba3974ce","value":2}},"f2becab02e8743c394fe4a963b444ece":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d93f7c3cec6047fbbd4e77dd64094561","placeholder":"​","style":"IPY_MODEL_bbdae41e1b53460a9e55bbd045a8b5ba","value":" 2/2 [00:00&lt;00:00, 22.74it/s]"}},"6ee960c10f6b4478aabdae65d4eed53d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0443fb9ce76433998693eb2a713a561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0eb34be06c749f49040cf03cda07321":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fdee202909f41968fa138d97d5a0378":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59e748961ca54b57b319a190ba3974ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d93f7c3cec6047fbbd4e77dd64094561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbdae41e1b53460a9e55bbd045a8b5ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training of the question answering model"],"metadata":{"id":"YIXKnJgUYF_-"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWKAo3K-SQKl","executionInfo":{"status":"ok","timestamp":1669139053970,"user_tz":300,"elapsed":23221,"user":{"displayName":"Adrien Heymans","userId":"09349593355027619302"}},"outputId":"9faeac98-ef0b-4ad2-8292-d60a2efdaf97"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mmZkB9TONsl","executionInfo":{"status":"ok","timestamp":1669139072293,"user_tz":300,"elapsed":18330,"user":{"displayName":"Adrien Heymans","userId":"09349593355027619302"}},"outputId":"b34f8371-0843-48bb-a00e-fab5257dfd4e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 32.9 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 58.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 50.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 32.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 69.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 74.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 73.8 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"]}]},{"cell_type":"markdown","source":["## Loading the dataset"],"metadata":{"id":"yv2jjokgYPv1"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264,"referenced_widgets":["9916cab4cbe64cd1841339c4d5473f70","e9ea35bfd9584c8fb345aed180991556","a5d81889a8b144d5b60723f00d95ebac","561e8705922c457aa00999261fae0723","012c12e5fbdb47e2835ca47fd2a6090b","a98f9087a2d64d86b6dda644886e8231","3cd1fa527dc5479eacdc7e1827f70a22","b76c40dfd5b846779cb3eb697b86c906","29c00a64b9684f3bb3b2833204843d78","665de3040ced488c8511ed21563261be","01f47e2879f64cbf92a29991c1ba7e46","f771b3defd0a40ff973053ff040c33cd","5f1781e47d9741ab9887f7b4c7afcafe","c6e1988110a34e489c4434e7da441717","ee34ea16cc4149e89d80e5da26271c16","9cd750a52ce64a46942b4e498dac85dd","482435bc6ac640a5b7997b8900295f0d","dbd2591c7e8843ffa39230d1e15d15f5","19ac1c358cd841cd984d5f3d40b3edbb","145ef5c283894b39b56d85a49a058963","427a0c800bf04ca9ba730ede4024fd92","3f29f012cf8d423ebabb45a2d3d2efc0","70abeb896bee40798ebf209c177c663b","6d9933b5475e49e79a23311961afe874","aecffd0c204b49b894534c81c6fb14bc","bd5203fe318b46e8b652647043cefd8c","2242e1d41d6b43958d9d65bc6d700cdb","ec854c2a9093427cb57468319faf3fe2","1e365e9435a949d3a3309e42e7b274a4","e5f2e2f7fafa48989780347faa3711df","79bf500604ef494cab62b730638b613d","852a9a7db8434d5387e5c3f637a3dce0","47ea46f9f6b842718db6c38e80ee8018","2bca99cb4d574268815f67b23f235152","e22aafd891464da39b4e67359db2b325","23a42a346ca841fa9ed086fda09894ca","f38cff33fb244f839dd6c39172d00e02","eaa4052e469a4333930405c3989beb82","ae2d9c01648248a2a43df01edfc77d01","2feba317fb784f0cbc54c76573517df6","83db239b602b4e30a249e1029c79940a","84ced86bd74440149cf3141173de4080","466d0a93c24e40f6a7afc0c9a6691ac0","93bccf280af448a992a809233b5f9eb8","24fb9610e69847d096ec998bd47a0110","c2e41d6aa61d42e48485889a16530acf","5ade08fc11a446358a8c2d3615165557","3a22971b035e4befacb4994675f79269","6918ed631092446cae9ead450aa175c8","57fc219be1c1474493eb8c7bcd22e198","95f7df71f115499ea8860ddb8e4aa36b","ac892b35e68d419caf4d7fc048eae54e","3cd41a40f27a4f298893b40b13d64888","64835cb77d7440738de43e1c9562ee2c","d8f90668029b42aaa6c1ab395bc4c2c8","e85bac5532514cbb833d2d9445720681","addfb9739cb64eed8ec82e5f920007bb","330f5a62fa5d4490bb5c2ee10dd01da7","0be57d91afbd4109901031c1b1ea69d7","223d787944dc40e4b5b5ff981e1a002f","d7fdebceeafc462c9efd780e5810c692","47eaf2833a7147e79f1a54194a3ce6d1","2a900d5f49dd4d35a3868e67bea9256f","4cfa206eab4f47cdadb2174792ce890c","d5e2a4777ef04edda7b021acc32b2a1d","a2cc8f1f991c4889ac9bf1840aa185c0","23c93efaf8d844f1b90391ded8348c27","fae253090d5e411c916708b9ee5d159a","9f8d54470fe84155a0eac42d22e70e81","f2becab02e8743c394fe4a963b444ece","6ee960c10f6b4478aabdae65d4eed53d","d0443fb9ce76433998693eb2a713a561","d0eb34be06c749f49040cf03cda07321","7fdee202909f41968fa138d97d5a0378","59e748961ca54b57b319a190ba3974ce","d93f7c3cec6047fbbd4e77dd64094561","bbdae41e1b53460a9e55bbd045a8b5ba"]},"id":"fttwbOrFN84D","executionInfo":{"status":"ok","timestamp":1669139095867,"user_tz":300,"elapsed":23597,"user":{"displayName":"Adrien Heymans","userId":"09349593355027619302"}},"outputId":"d8dd5359-0f5d-4e5a-f654-02e2252fbf96"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/5.19k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9916cab4cbe64cd1841339c4d5473f70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f771b3defd0a40ff973053ff040c33cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/15.5k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70abeb896bee40798ebf209c177c663b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset cuad/default to /root/.cache/huggingface/datasets/cuad/default/1.0.0/01ed7dc61ab84230462731422e77cbb6f54ea8590b22a2d881b594f4d7f3746c...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/18.3M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bca99cb4d574268815f67b23f235152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/22450 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24fb9610e69847d096ec998bd47a0110"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/4182 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e85bac5532514cbb833d2d9445720681"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset cuad downloaded and prepared to /root/.cache/huggingface/datasets/cuad/default/1.0.0/01ed7dc61ab84230462731422e77cbb6f54ea8590b22a2d881b594f4d7f3746c. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23c93efaf8d844f1b90391ded8348c27"}},"metadata":{}}],"source":["from datasets import load_dataset\n","\n","cuad = load_dataset(\"cuad\")"]},{"cell_type":"markdown","source":["## Tokenization"],"metadata":{"id":"5wgjiiOpYVVl"}},{"cell_type":"markdown","source":["### Downloading the tokenizer"],"metadata":{"id":"soK7pXIaYeVe"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")"],"metadata":{"id":"vdZMDcPGOMQo","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["bb4dca2e5c7a4e46b338bd70cc0472cc","684e16700fc74cf68b16ff98c9b8fee9","257c869dd2494ffd94e71dd9e4ff0600","ded8cdbcbcca48e5ac8288297f9b87db","595cc3ea92854eb2a9b6554a7ce1c067","1826800942a141f6a0620c495e6e58aa","cca594a05cd046d29e9cdc0fe75ba2fb","320e3b510d0d432cbf01a2a858042293","46205815ab6d4690821495dd6a25ad8c","289b8423282a438aa68b774e6e9345db","00051fa901f143ec8f10e66da4cbb777","e2089cd3994446e8a728cdcd0a61b80d","29483930506245e484b82a60fd15e7fd","d6f5a7d95ef945bda552d808e76e0b11","4cc26f38c1e8456bac0115cfd8bae039","c6e1a00d9bd4474fb49385e012f2a36d","0db5eae65f2c4e7ab4d0bc9726ede44a","83823b89ecdd464b9d2ed5ff6da55d48","5620db8cc67c4529874d3b85f3fb9eaf","c0fcf1046776461bb2080246a320f5cf","dd73c9ba1c204118a5674c77b644c40e","0c15942888bb46d288ca013975b023a0","6505781354ac45f7912e30fdd53202eb","fb783fb42d5e43d9a88c823c024a8230","a3a54d1b4c37497885377e7301a950ad","36410bbc25e340b6a993a40414742af9","f300ed208eac411c9751e4cb8f8dcd09","65ca383e49d24a45ac786c7c531134d4","831f670d5e3b4304af1401590af1e25f","2757ba1673eb4c518efa21c1dc5269e9","59e1132e254948cfb5996e4d4030445e","0609ceb4425948b384135678e99cae10","55d9e7bff04b47a2aa2d274dedd913e2","f16df48d576f41e0bfb4b3c7b0bcf75b","f25514de9baa415ca31dcf51633c9527","1f6331d4052a4712b6f36adaba1fc117","7912d8bd0ef24119893408dfc4677406","b9857309f2cd429fa730cd4f9be37115","46fb4552f4f74a5398a67f0e08db0bf5","14f4b4485c72409196e435383be28b13","43e70341aace4278b93cc44a593896dc","02b1fc6afc9c4e6da75e3f245a11c3ef","dbc605b44cc440c88525556b14195c58","bd1dfedf5c084c228e51349bf6198827"]},"executionInfo":{"status":"ok","timestamp":1668650391200,"user_tz":300,"elapsed":13954,"user":{"displayName":"Adrien Heymans","userId":"17628879283543790980"}},"outputId":"b470b71f-2c70-4a45-a538-3e996ece57e2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/152 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4dca2e5c7a4e46b338bd70cc0472cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/508 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2089cd3994446e8a728cdcd0a61b80d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6505781354ac45f7912e30fdd53202eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f16df48d576f41e0bfb4b3c7b0bcf75b"}},"metadata":{}}]},{"cell_type":"markdown","source":["### Pre-processing function\n","Used to add the \"end\" index of the answers "],"metadata":{"id":"Jla5Ae-VYiY0"}},{"cell_type":"code","source":["def preprocess_function(examples):\n","    #print(examples[\"context\"][0])\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=384,\n","        truncation=\"only_second\",\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    offset_mapping = inputs.pop(\"offset_mapping\")\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, offset in enumerate(offset_mapping):\n","        answer = answers[i]\n","        if (len(answer[\"answer_start\"])==0):\n","          start_char = -1\n","        else:\n","          start_char = answer[\"answer_start\"][0]\n","\n","        if (len(answer[\"answer_start\"])==0):\n","          end_char = -1\n","        else:\n","          end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","        sequence_ids = inputs.sequence_ids(i)\n","\n","        # Find the start and end of the context\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        # If the answer is not fully inside the context, label it (0, 0)\n","        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","        else:\n","            # Otherwise it's the start and end token positions\n","            idx = context_start\n","            while idx <= context_end and offset[idx][0] <= start_char:\n","                idx += 1\n","            start_positions.append(idx - 1)\n","\n","            idx = context_end\n","            while idx >= context_start and offset[idx][1] >= end_char:\n","                idx -= 1\n","            end_positions.append(idx + 1)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs"],"metadata":{"id":"H-8rM7t9OM6B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tokenization of the train and validation set "],"metadata":{"id":"ZLSWr3MfYs6b"}},{"cell_type":"code","source":["print(cuad[\"train\"].column_names)"],"metadata":{"id":"A7829iXMgij6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668650400193,"user_tz":300,"elapsed":417,"user":{"displayName":"Adrien Heymans","userId":"17628879283543790980"}},"outputId":"7d3fb49a-cb9c-4319-d3ff-35817644fa5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['id', 'title', 'context', 'question', 'answers']\n"]}]},{"cell_type":"code","source":["tokenized_cuad = cuad.map(preprocess_function, batched=True, remove_columns=cuad[\"train\"].column_names)"],"metadata":{"id":"Ze-WQHNIQv2G","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["1de739696ea444729db0788e2b1b2ed8","92662c869f8f41799729bd8592ee685a","393f18bf8fc94064b2e5917536e99182","acd17be5aa46494fa2020b599ad80e64","a84e97fb97004b479d353d4b0d603d8f","aa883edee55948c99581ef9cff2747b4","84991917267c4ce3ae1e09e96af20b3d","f247859b5535421bbe5a05bac7f5bfb6","902d050298fe4362870626b3a02cb4f1","fc5a3b48e2b6408dacd2ebafa4a96707","813b15fcb17840ae9581dbbb41c1f783","d91dd32ea36b4a078f6c232df0072b65","691f58131adf471dbf41caa2b995d157","83702624b3394d5a95c4c1094a31f341","f4e7eb54396249aab0fe2a0596eae3f5","72491821136c4516b51464e7f63ab940","fd3eac1599a74f899afb0df49787f602","490772e75bc344a89f232456177261c3","29df3027a21349988da0f9a234d2082d","b5ac247ec7884cdab88df9f1a67e5476","73bcddbd8e274a85afc93d9de0c617cc","05e68169ddec477a81de8f9dabb52006"]},"executionInfo":{"status":"ok","timestamp":1668651218894,"user_tz":300,"elapsed":779218,"user":{"displayName":"Adrien Heymans","userId":"17628879283543790980"}},"outputId":"a9547143-38bb-4906-dce6-f415f8ad1415"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/23 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1de739696ea444729db0788e2b1b2ed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d91dd32ea36b4a078f6c232df0072b65"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Initialization of the data collectors"],"metadata":{"id":"5mxo9LPQY2Dd"}},{"cell_type":"code","source":["from transformers import DefaultDataCollator\n","\n","data_collator = DefaultDataCollator()"],"metadata":{"id":"vf6VdSPKUZmu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Downloading the model"],"metadata":{"id":"5BavLF1-Y6Im"}},{"cell_type":"code","source":["from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")"],"metadata":{"id":"CArY5l1qUguP","colab":{"base_uri":"https://localhost:8080/","height":77,"referenced_widgets":["31ac8b722fd348059b8e0c9961d85d60","d54603d1b0c34399be9250bdab7b95bc","5bad802757624904beb52fb178303684","e5cc67e6d986406e99b16be1a3224ebf","1b85f54505df4764b5295f890e686f4a","926badbd62f44358b6e9821b6de9cdc6","d020f21b4b0f4763911708ce771759d9","aeb8f8fb93be44edbaeada8e8c04b705","5a7385f8362e418485bb53912642b985","a754fc68c8674fe49d2bab2c606f62f1","0fd4e9bc5ffa430ea03d8ba08da19af6"]},"executionInfo":{"status":"ok","timestamp":1668651236631,"user_tz":300,"elapsed":15565,"user":{"displayName":"Adrien Heymans","userId":"17628879283543790980"}},"outputId":"7945d69d-b874-4f77-bcc1-1243832a7327"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/433M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31ac8b722fd348059b8e0c9961d85d60"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Training of the model"],"metadata":{"id":"J1E6Yr_aY9lM"}},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/CSI5386 : Assignment 2/trained-models/bert-CUAD\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    save_steps = 1000\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_cuad[\"train\"],\n","    eval_dataset=tokenized_cuad[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train(resume_from_checkpoint = False)"],"metadata":{"id":"Z0Lux_FSUnBH","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1668656970426,"user_tz":300,"elapsed":5683254,"user":{"displayName":"Adrien Heymans","userId":"17628879283543790980"}},"outputId":"ad8acdee-2b61-40aa-dec4-1874579c944f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 22450\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4212\n","  Number of trainable parameters = 107721218\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4212' max='4212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4212/4212 1:34:41, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.326300</td>\n","      <td>0.148649</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.254800</td>\n","      <td>0.123772</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.219000</td>\n","      <td>0.132489</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-1000/config.json\n","Model weights saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 4182\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-2000\n","Configuration saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-2000/config.json\n","Model weights saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-2000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 4182\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-3000\n","Configuration saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-3000/config.json\n","Model weights saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-3000/special_tokens_map.json\n","Saving model checkpoint to /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\n","Configuration saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model weights saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 4182\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4212, training_loss=0.26932502177819, metrics={'train_runtime': 5682.7521, 'train_samples_per_second': 11.852, 'train_steps_per_second': 0.741, 'total_flos': 1.31987524246272e+16, 'train_loss': 0.26932502177819, 'epoch': 3.0})"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Predictions"],"metadata":{"id":"rKlC56qmkM92"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"id":"PAnvTdAwkroU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668541318647,"user_tz":300,"elapsed":8226,"user":{"displayName":"Adrien Heymans","userId":"06415863972857069345"}},"outputId":"b8811cc7-0def-4d19-d5a7-144fe801d756"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import os"],"metadata":{"id":"R2eae359k7fs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Importing test dataset"],"metadata":{"id":"WnMsSaUblGCM"}},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import pipeline\n","cuad = load_dataset(\"cuad\")"],"metadata":{"id":"0PgnGq2znBlQ","colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["537a9ab0e62a4d7f82ac639698a8c6f2","1c7f5152c00b46788ccd678845ea39f3","be460ae54b044c168d9baf5b066837a8","d7984446a4114932969c78899ba02448","7351950d668a420d947fdb55e1ea76cf","61c988f3d6f44d8d993d8753fe039bbb","ee396aa67bbb480ebf9878f11e252bc3","89311c8c4dca4679b31f38719da537e2","dcabd066470e40f980bcec7fa9e9bd93","f9b6e62759f9485fba4f3cd2051dbcaa","35d211efbb6b4f59b8e23dcd47cb120c"]},"executionInfo":{"status":"ok","timestamp":1668657167926,"user_tz":300,"elapsed":5720,"user":{"displayName":"Adrien Heymans","userId":"17628879283543790980"}},"outputId":"2d09dc27-311f-4bad-c1f5-e46acd8edff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset cuad (/root/.cache/huggingface/datasets/cuad/default/1.0.0/01ed7dc61ab84230462731422e77cbb6f54ea8590b22a2d881b594f4d7f3746c)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"537a9ab0e62a4d7f82ac639698a8c6f2"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Functions for evaluation of the model "],"metadata":{"id":"AExvC5kGZbV9"}},{"cell_type":"code","source":["def get_prediction(qid):\n","    # given a question id (qas_id or qid), load the example, get the model outputs and generate an answer\n","\n","    found = False\n","    index=0\n","    for index in range(len(cuad[\"test\"][\"id\"])):\n","      if (cuad[\"test\"][\"id\"][index]==qid):\n","        found = True\n","        break\n","    \n","    question_curr = cuad[\"test\"][\"question\"][index]\n","    context_curr = cuad[\"test\"][\"context\"][index]\n","\n","    # Loading the model \n","    question_answering = pipeline(task=\"question-answering\",model=\"/content/drive/MyDrive/CSI5386 : Assignment 2/trained-models/bert-CUAD/checkpoint-4000\",tokenizer=\"/content/drive/MyDrive/CSI5386 : Assignment 2/trained-models/bert-CUAD/checkpoint-4000\",batch_size=20,device=torch.cuda.current_device(),num_workers=20)\n","\n","    result = question_answering(question=question_curr, context=context_curr)\n","    \n","    \n","    return result"],"metadata":{"id":"4rSgrvnvZeJL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# these functions are heavily influenced by the HF squad_metrics.py script\n","def normalize_text(s):\n","    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n","    import string, re\n","\n","    def remove_articles(text):\n","        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n","        return re.sub(regex, \" \", text)\n","\n","    def white_space_fix(text):\n","        return \" \".join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return \"\".join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        #print(\"TEXT : \"+text)\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","def compute_exact_match(prediction, truth):\n","    return int(normalize_text(prediction) == normalize_text(truth))\n","\n","def compute_f1(prediction, truth):\n","    pred_tokens = normalize_text(prediction).split()\n","    truth_tokens = normalize_text(truth).split()\n","    \n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","    \n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","    \n","    # if there are no common tokens then f1 = 0\n","    if len(common_tokens) == 0:\n","        return 0\n","    \n","    prec = len(common_tokens) / len(pred_tokens)\n","    rec = len(common_tokens) / len(truth_tokens)\n","    \n","    return 2 * (prec * rec) / (prec + rec)\n","\n","def get_gold_answers(example):\n","    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n","    \n","    if (len(example[\"text\"])==0):\n","      gold_answers = [\"\"]\n","    else:\n","      gold_answers = example[\"text\"]\n","\n","    # if gold_answers doesn't exist it's because this is a negative example - \n","    # the only correct answer is an empty string\n","    \n","        \n","    return gold_answers"],"metadata":{"id":"FWKC-5JxZ6EC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation of model\n","Using the validation set "],"metadata":{"id":"qOLvB0yj6A-n"}},{"cell_type":"code","source":["from tqdm import tqdm\n","import json\n","\n","# Creating a JSON file to store the rsults\n","filename = \"/content/drive/MyDrive/CSI5386 : Assignment 2/trained-models/bert-CUAD/predictions-bert-cuad-checkpoint-4000.json\"\n","with open(filename, \"w\") as file:\n","    json.dump(\"{}\", file)\n","lst = [{}]\n","# Initialiazing the varibalers for the scores\n","average_f1 = 0\n","average_em = 0\n","\n","# Looping through the testing set, using a progress bar. We will also save the prediction to a JSON file to avoid data loss\n","with tqdm(\n","    bar_format=\"{postfix} | Elapsed: {elapsed} | {rate_fmt}\",\n","    postfix=average_f1,\n",") as t:\n","    for index in range(len(cuad[\"test\"][\"title\"])):\n","      \n","      # Retrieving the predictions\n","      prediction = get_prediction(cuad[\"test\"][\"id\"][index])\n","      example = cuad[\"test\"][\"answers\"][index]\n","\n","      # Retrieving the golg answer\n","      gold_answers = get_gold_answers(example)\n","\n","      # Computing the scores\n","      em_score = max((compute_exact_match(prediction[\"answer\"], answer)) for answer in gold_answers)\n","      f1_score = max((compute_f1(prediction[\"answer\"], answer)) for answer in gold_answers)\n","\n","      # Keeping track of the Exact Matcb Score and F1 score\n","      average_f1 = f1_score + average_f1\n","      average_em = em_score + average_em\n","\n","      # Updating the progress bar\n","      t.postfix = \"Index : \"+str((index))+\"/\"+str(len(cuad[\"test\"][\"title\"]))+ \" | F1 : \"+str((average_f1/(index+1)))+\" | EM : \"+str(average_em/(index+1)) \n","      t.update()\n","\n","      # Saving the prediction to the JSON file\n","      # with open(filename,\"r\") as file:\n","      #   predictionJSON=json.load(file)\n","\n","      lst.append({cuad[\"test\"][\"id\"][index]:prediction[\"answer\"],\"score\":prediction[\"score\"]})\n","      \n","      with open(filename, \"w\") as file:\n","        json.dump(lst, file,indent=2)\n"],"metadata":{"id":"HVQLZlfC6DQ9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d20c618-3dc0-40d3-eea0-17874766857d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1825/4182 | F1 : 0.17566620459602864 | EM : 0.13745892661555312 | Elapsed: 3:16:58 |  7.98s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1826/4182 | F1 : 0.1756257167529297 | EM : 0.13738368910782703 | Elapsed: 3:17:08 |  8.63s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1827/4182 | F1 : 0.1755296414155375 | EM : 0.13730853391684902 | Elapsed: 3:17:16 |  8.39s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1828/4182 | F1 : 0.17543367113592268 | EM : 0.13723346090759977 | Elapsed: 3:17:24 |  8.22s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1829/4182 | F1 : 0.17533780574185934 | EM : 0.1371584699453552 | Elapsed: 3:17:32 |  8.09s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1830/4182 | F1 : 0.17524204506149785 | EM : 0.1370835608956854 | Elapsed: 3:17:40 |  8.03s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1831/4182 | F1 : 0.17514638892336384 | EM : 0.13700873362445415 | Elapsed: 3:17:48 |  8.00s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1832/4182 | F1 : 0.1750508371563571 | EM : 0.13693398799781778 | Elapsed: 3:17:55 |  7.97s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1833/4182 | F1 : 0.17495538958975057 | EM : 0.13685932388222466 | Elapsed: 3:18:04 |  8.12s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1834/4182 | F1 : 0.17486004605318942 | EM : 0.13678474114441416 | Elapsed: 3:18:13 |  8.39s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1835/4182 | F1 : 0.17476480637668984 | EM : 0.13671023965141613 | Elapsed: 3:18:21 |  8.30s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1836/4182 | F1 : 0.1746696703906383 | EM : 0.1366358192705498 | Elapsed: 3:18:29 |  8.23s/it  loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1837/4182 | F1 : 0.17457463792579028 | EM : 0.1365614798694233 | Elapsed: 3:18:37 |  8.20s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1838/4182 | F1 : 0.17447970881326946 | EM : 0.13648722131593258 | Elapsed: 3:18:48 |  8.88s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1839/4182 | F1 : 0.1743848828845666 | EM : 0.13641304347826086 | Elapsed: 3:18:56 |  8.62s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1840/4182 | F1 : 0.1742901599715386 | EM : 0.13633894622487777 | Elapsed: 3:19:04 |  8.40s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1841/4182 | F1 : 0.17419553990640746 | EM : 0.13626492942453855 | Elapsed: 3:19:14 |  8.91s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1842/4182 | F1 : 0.17464361611915494 | EM : 0.1367335865436788 | Elapsed: 3:19:22 |  8.59s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1843/4182 | F1 : 0.17454890699978448 | EM : 0.13665943600867678 | Elapsed: 3:19:29 |  8.39s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1844/4182 | F1 : 0.17445430054612604 | EM : 0.13658536585365855 | Elapsed: 3:19:37 |  8.27s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1845/4182 | F1 : 0.17490150840065144 | EM : 0.13705308775731312 | Elapsed: 3:19:48 |  8.94s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1846/4182 | F1 : 0.17480681348543722 | EM : 0.136978884677856 | Elapsed: 3:19:58 |  9.36s/it  loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1847/4182 | F1 : 0.17525334659502304 | EM : 0.13744588744588745 | Elapsed: 3:20:09 |  9.66s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1848/4182 | F1 : 0.17515856382239187 | EM : 0.13737155219037317 | Elapsed: 3:20:21 | 10.54s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1849/4182 | F1 : 0.175063883517623 | EM : 0.1372972972972973 | Elapsed: 3:20:32 | 10.53s/it   loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1850/4182 | F1 : 0.17496930551464213 | EM : 0.13722312263641276 | Elapsed: 3:20:43 | 10.63s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1851/4182 | F1 : 0.17487482964773357 | EM : 0.13714902807775378 | Elapsed: 3:20:53 | 10.60s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1852/4182 | F1 : 0.17478045575153944 | EM : 0.13707501349163517 | Elapsed: 3:21:04 | 10.63s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1853/4182 | F1 : 0.17522555798684064 | EM : 0.13754045307443366 | Elapsed: 3:21:15 | 10.92s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1854/4182 | F1 : 0.17513109676959707 | EM : 0.13746630727762804 | Elapsed: 3:21:28 | 11.47s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1855/4182 | F1 : 0.17503673734245828 | EM : 0.13739224137931033 | Elapsed: 3:21:40 | 11.71s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1856/4182 | F1 : 0.17548098250274774 | EM : 0.13785675821217017 | Elapsed: 3:21:52 | 11.61s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1857/4182 | F1 : 0.17592474946587866 | EM : 0.13832077502691065 | Elapsed: 3:22:03 | 11.45s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1858/4182 | F1 : 0.175830115388705 | EM : 0.13824636901559978 | Elapsed: 3:22:14 | 11.44s/it  loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1859/4182 | F1 : 0.17573558306860354 | EM : 0.1381720430107527 | Elapsed: 3:22:27 | 11.89s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1860/4182 | F1 : 0.17573239969283036 | EM : 0.13809779688339602 | Elapsed: 3:22:38 | 11.63s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1861/4182 | F1 : 0.1761750783181296 | EM : 0.1385606874328679 | Elapsed: 3:22:52 | 12.26s/it  loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1862/4182 | F1 : 0.17608051305869957 | EM : 0.13848631239935588 | Elapsed: 3:23:04 | 12.08s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1863/4182 | F1 : 0.17598604926414016 | EM : 0.13841201716738197 | Elapsed: 3:23:15 | 11.75s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1864/4182 | F1 : 0.1759072285981789 | EM : 0.1383378016085791 | Elapsed: 3:23:28 | 12.14s/it  loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1865/4182 | F1 : 0.1758129589151145 | EM : 0.1382636655948553 | Elapsed: 3:23:39 | 11.82s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1866/4182 | F1 : 0.17576640076298478 | EM : 0.13818960899839314 | Elapsed: 3:23:50 | 11.62s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1867/4182 | F1 : 0.17567230740069195 | EM : 0.1381156316916488 | Elapsed: 3:24:01 | 11.47s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1868/4182 | F1 : 0.1755783147268553 | EM : 0.13804173354735153 | Elapsed: 3:24:12 | 11.40s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1869/4182 | F1 : 0.17548442257994254 | EM : 0.13796791443850268 | Elapsed: 3:24:25 | 11.65s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1870/4182 | F1 : 0.17539063079876674 | EM : 0.1378941742383752 | Elapsed: 3:24:35 | 11.39s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1871/4182 | F1 : 0.17529693922248535 | EM : 0.13782051282051283 | Elapsed: 3:24:46 | 11.25s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1872/4182 | F1 : 0.17520334769059934 | EM : 0.13774693005872932 | Elapsed: 3:24:57 | 11.21s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1873/4182 | F1 : 0.17510985604295226 | EM : 0.1376734258271078 | Elapsed: 3:25:09 | 11.27s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1874/4182 | F1 : 0.17501646411972938 | EM : 0.1376 | Elapsed: 3:25:20 | 11.24s/it            loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1875/4182 | F1 : 0.17492317176145658 | EM : 0.13752665245202558 | Elapsed: 3:25:33 | 11.87s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1876/4182 | F1 : 0.17482997880899975 | EM : 0.1374533830580714 | Elapsed: 3:25:45 | 11.73s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1877/4182 | F1 : 0.17473688510356367 | EM : 0.13738019169329074 | Elapsed: 3:25:56 | 11.64s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1878/4182 | F1 : 0.1746438904866911 | EM : 0.1373070782331027 | Elapsed: 3:26:07 | 11.46s/it  loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1879/4182 | F1 : 0.17508290969387902 | EM : 0.1377659574468085 | Elapsed: 3:26:19 | 11.44s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1880/4182 | F1 : 0.17503708618467914 | EM : 0.13769271664008506 | Elapsed: 3:26:32 | 12.02s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1881/4182 | F1 : 0.1749776392179162 | EM : 0.13761955366631243 | Elapsed: 3:26:43 | 11.81s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1882/4182 | F1 : 0.17488471429002564 | EM : 0.137546468401487 | Elapsed: 3:26:55 | 11.90s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1883/4182 | F1 : 0.17481521924207766 | EM : 0.13747346072186836 | Elapsed: 3:27:06 | 11.61s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1884/4182 | F1 : 0.1752529830514983 | EM : 0.13793103448275862 | Elapsed: 3:27:18 | 11.52s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1885/4182 | F1 : 0.17516005994277536 | EM : 0.1378579003181336 | Elapsed: 3:27:31 | 12.11s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1886/4182 | F1 : 0.1755971770281263 | EM : 0.1383147853736089 | Elapsed: 3:27:44 | 12.27s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1887/4182 | F1 : 0.17550417004876817 | EM : 0.1382415254237288 | Elapsed: 3:27:56 | 12.34s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1888/4182 | F1 : 0.17594064216626487 | EM : 0.13869772366331393 | Elapsed: 3:28:09 | 12.36s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1889/4182 | F1 : 0.17637665240850495 | EM : 0.13915343915343914 | Elapsed: 3:28:21 | 12.42s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1890/4182 | F1 : 0.17639185682559627 | EM : 0.13907985193019567 | Elapsed: 3:28:36 | 13.15s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1891/4182 | F1 : 0.17648687401731722 | EM : 0.13900634249471458 | Elapsed: 3:28:49 | 13.13s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1892/4182 | F1 : 0.1765817908210913 | EM : 0.13893291072371897 | Elapsed: 3:29:02 | 13.03s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1893/4182 | F1 : 0.17648855861896823 | EM : 0.13885955649419218 | Elapsed: 3:29:15 | 12.96s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1894/4182 | F1 : 0.1769231293004358 | EM : 0.13931398416886542 | Elapsed: 3:29:28 | 13.19s/it loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1895/4182 | F1 : 0.1768728706104362 | EM : 0.13924050632911392 | Elapsed: 3:29:42 | 13.19s/itloading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"language\": \"english\",\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"name\": \"Bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Question-Answering-main/trained_models/bert-CUAD/checkpoint-4000.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n",", Index : 1896/4182 | F1 : 0.176810641121138 | EM : 0.13916710595677384 | Elapsed: 3:29:56 | 13.69s/it "]}]}]}